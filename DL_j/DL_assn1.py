# -*- coding: utf-8 -*-
"""DL_Assignment_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LK0Wqg5OoJ8GhTVb1vjZwX01_HNQJbz6

DL 1
"""

# Commented out IPython magic to ensure Python compatibility.

# import libraries
import pandas as pd
import numpy as np
import tensorflow as tf

from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

data=pd.read_csv("/content/HousingData.csv")

# See head of the dataset
data.head()

data.isnull().sum().sort_values(ascending=False)

data = data.fillna(data.mean())

data.isnull().sum().sort_values(ascending=False)

data.describe()

data.corr()

print('Our data set contains {} rows and {} columns'.format(data.shape[0],data.shape[1]))

data.info()

pos = 1
fig = plt.figure(figsize=(16,24))
for i in data.columns:
    ax = fig.add_subplot(7,2,pos)
    pos = pos + 1
    sns.distplot(data[i],ax=ax)

fig = plt.figure(figsize=(16,12))
ax = fig.add_subplot(111)
sns.heatmap(data.corr(),annot=True)

X = data[['RM', 'ZN', 'CHAS', 'TAX', 'DIS']].values
y = data['MEDV'].values

scaler = StandardScaler()
scaled_data = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size =0.2,
                                                    random_state = 4)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=1, input_shape=[5])
])

# compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')

model.fit(xtrain, ytrain, epochs=100)

# evaluate the model
model.evaluate(xtest, ytest)
